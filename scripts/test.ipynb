{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8220980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cpu_act, Avg Skew: 5.40, Target Skew: -3.42\n",
      "Dataset: pol, Avg Skew: 4.78, Target Skew: 0.92\n",
      "Dataset: elevators, Avg Skew: -0.60, Target Skew: 2.42\n",
      "Dataset: wine_quality, Avg Skew: 1.36, Target Skew: 0.19\n",
      "Dataset: Ailerons, Avg Skew: 0.60, Target Skew: -1.35\n",
      "Dataset: houses, Avg Skew: 2.23, Target Skew: -0.17\n",
      "Dataset: house_16H, Avg Skew: 6.14, Target Skew: -3.43\n",
      "Dataset: diamonds, Avg Skew: 1.03, Target Skew: 0.12\n",
      "Dataset: Brazilian_houses, Avg Skew: 30.23, Target Skew: 0.30\n",
      "Dataset: Bike_Sharing_Demand, Avg Skew: 0.06, Target Skew: 1.28\n",
      "Dataset: nyc-taxi-green-dec-2016, Avg Skew: 2.56, Target Skew: -0.00\n",
      "Dataset: house_sales, Avg Skew: 2.40, Target Skew: 0.43\n",
      "Dataset: sulfur, Avg Skew: -0.03, Target Skew: 6.72\n",
      "Dataset: medical_charges, Avg Skew: 5.02, Target Skew: 0.88\n",
      "Dataset: MiamiHousing2016, Avg Skew: 0.93, Target Skew: 0.74\n",
      "Dataset: superconduct, Avg Skew: 0.67, Target Skew: 0.86\n",
      "Dataset: yprop_4_1, Avg Skew: -0.29, Target Skew: -2.23\n",
      "Dataset: abalone, Avg Skew: 0.62, Target Skew: 1.11\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "from openml.tasks import list_tasks, TaskType\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, randint, loguniform, ttest_rel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from joblib import Memory\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "# Import our binning class.\n",
    "# DataBinner should be defined as in our previous example.\n",
    "from src import DataBinner  \n",
    "\n",
    "def get_memory_for_dataset(bin_method, task_id, seed):\n",
    "    \"\"\"\n",
    "    Create (or reuse) a cache folder specific to this dataset/task.\n",
    "    This way, each dataset version has its own cache files.\n",
    "    \"\"\"\n",
    "    cache_dir = os.path.join(\"../cached_datasets\", bin_method, str(task_id), str(seed))\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    return Memory(location=cache_dir, verbose=0)\n",
    "\n",
    "# -------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"sklearn\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightgbm\").setLevel(logging.ERROR)\n",
    "\n",
    "# Parameter distribution for sklearn\n",
    "param_dist_sklearn = {\n",
    "    'gradientboostingregressor__n_estimators': randint(20, 300),\n",
    "    'gradientboostingregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'gradientboostingregressor__max_depth': randint(3, 6),\n",
    "    'gradientboostingregressor__subsample': uniform(0.5, 0.5),\n",
    "    'gradientboostingregressor__max_features': uniform(0.5, 0.5)}\n",
    "\n",
    "# Parameter distribution for LightGBM\n",
    "param_dist_lgbm = {\n",
    "    'lgbmregressor__n_estimators': randint(20, 300),\n",
    "    'lgbmregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'lgbmregressor__num_leaves': randint(8, 64),\n",
    "    'lgbmregressor__subsample': uniform(0.5, 0.5),\n",
    "    'lgbmregressor__colsample_bytree': uniform(0.5, 0.5)\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (GradientBoostingRegressor(), \"SKL\", param_dist_sklearn),\n",
    "    (LGBMRegressor(verbosity=-1, n_jobs=1, random_state=42), \"LGBM\", param_dist_lgbm), \n",
    "]\n",
    "\n",
    "# List of binning methods to experiment with\n",
    "binning_methods = [\n",
    "    #'exact',\n",
    "    'kmeans',\n",
    "    'quantile',\n",
    "    'linspace'\n",
    "]\n",
    "\n",
    "# Retrieve a benchmark suite from OpenML and select a task\n",
    "benchmark_suite = openml.study.get_suite(336) #337 for classification\n",
    "for benchmark_id in range(18):\n",
    "    task_id = benchmark_suite.tasks[benchmark_id]\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    dataset = task.get_dataset()\n",
    "    name = dataset.name\n",
    "    X, y, _, _ = dataset.get_data(target=task.target_name)\n",
    "    avg_skew = np.mean([skew(X[col]) for col in X.columns])\n",
    "    y_skew = skew(y)\n",
    "    print(f\"Dataset: {name}, Avg Skew: {avg_skew:.2f}, Target Skew: {y_skew:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATASET abalone with 4177.0 observations and 9.0 features =====\n",
      "category\n",
      "0\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "from openml.tasks import list_tasks, TaskType\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, randint, loguniform, ttest_rel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from joblib import Memory\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Import our binning class.\n",
    "# DataBinner should be defined as in our previous example.\n",
    "from src import DataBinner  \n",
    "\n",
    "def get_memory_for_dataset(bin_method, task_id, seed):\n",
    "    \"\"\"\n",
    "    Create (or reuse) a cache folder specific to this dataset/task.\n",
    "    This way, each dataset version has its own cache files.\n",
    "    \"\"\"\n",
    "    cache_dir = os.path.join(\"../cached_datasets\", bin_method, str(task_id), str(seed))\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    return Memory(location=cache_dir, verbose=0)\n",
    "\n",
    "# -------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"sklearn\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightgbm\").setLevel(logging.ERROR)\n",
    "\n",
    "# Parameter distribution for sklearn\n",
    "param_dist_sklearn = {\n",
    "    'gradientboostingregressor__n_estimators': randint(20, 300),\n",
    "    'gradientboostingregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'gradientboostingregressor__max_depth': randint(3, 6),\n",
    "    'gradientboostingregressor__subsample': uniform(0.5, 0.5),\n",
    "    'gradientboostingregressor__max_features': uniform(0.5, 0.5)}\n",
    "\n",
    "# Parameter distribution for LightGBM\n",
    "param_dist_lgbm = {\n",
    "    'lgbmregressor__n_estimators': randint(20, 300),\n",
    "    'lgbmregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'lgbmregressor__num_leaves': randint(8, 64),\n",
    "    'lgbmregressor__subsample': uniform(0.5, 0.5),\n",
    "    'lgbmregressor__colsample_bytree': uniform(0.5, 0.5)\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (GradientBoostingRegressor(), \"SKL\", param_dist_sklearn),\n",
    "    #(LGBMRegressor(verbosity=-1, n_jobs=1, random_state=42), \"LGBM\", param_dist_lgbm), \n",
    "]\n",
    "\n",
    "# List of binning methods to experiment with\n",
    "binning_methods = [\n",
    "    #'exact',\n",
    "    'kmeans',\n",
    "    'quantile',\n",
    "    'linspace'\n",
    "]\n",
    "\n",
    "# Retrieve a benchmark suite from OpenML and select a task\n",
    "benchmark_suite = openml.study.get_suite(353) #337 for classification\n",
    "benchmark_id = 0\n",
    "task_id = benchmark_suite.tasks[benchmark_id]\n",
    "\n",
    "task = openml.tasks.get_task(task_id)\n",
    "dataset = task.get_dataset()\n",
    "name = dataset.name\n",
    "obs = dataset.qualities['NumberOfInstances']\n",
    "features = dataset.qualities['NumberOfFeatures']\n",
    "print(f\"===== DATASET {name} with {obs} observations and {features} features =====\")\n",
    "\n",
    "\n",
    "# Get X and y\n",
    "X, y = task.get_X_and_y(dataset_format='dataframe')\n",
    "transform_cols = []\n",
    "for col_idx, dtype in enumerate(X.dtypes):\n",
    "    if dtype == 'object' or dtype == 'category':\n",
    "        transform_cols.append(X.columns[col_idx])\n",
    "\n",
    "# Transform categorical columns to one-hot\n",
    "X = pd.get_dummies(X, columns=transform_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db726bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.  0.  1.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def centred_linspace(span, n_modes):\n",
    "    if n_modes == 1:\n",
    "        return np.array([0.0])\n",
    "    return np.linspace(-span, span, n_modes)\n",
    "\n",
    "\n",
    "def make_synthetic(n_obs, n_features, n_modes, mode_size, skew_factor, skew_scale, rng):\n",
    "    \"\"\"Return DataFrame X and target y.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_obs : int\n",
    "        Number of observations.\n",
    "    n_features : int\n",
    "        Number of features.\n",
    "    n_modes : int\n",
    "        Number of modes in the multimodal distribution.\n",
    "    mode_size : float\n",
    "        Difference between modes.\n",
    "    skew_factor : float\n",
    "        Probability of adding skewness.\n",
    "    skew_scale : float\n",
    "        Scale of the skewness.\n",
    "    rng : np.random.Generator\n",
    "        Random number generator.\n",
    "    Returns:\n",
    "    --------\n",
    "    X : pd.DataFrame\n",
    "        DataFrame with n_obs rows and n_features columns.\n",
    "    \"\"\"\n",
    "    data = np.zeros((n_obs, n_features))\n",
    "    # --- Multimodal component\n",
    "    means = np.linspace(0, mode_size * (n_modes - 1), n_modes)\n",
    "    for j in range(n_features):\n",
    "        mode_choice = rng.integers(0, n_modes, size=n_obs)\n",
    "        data[:, j] = rng.normal(loc=means[mode_choice], scale=1.0)\n",
    "        data[:, j] = (data[:, j] - data[:, j].mean()) / data[:, j].std() # Standardizing\n",
    "    \n",
    "    # --- Skewness: add positive outliers with prob = skew_factor\n",
    "    if skew_factor > 0:\n",
    "        mask = rng.random(size=data.shape) < skew_factor\n",
    "        data[mask] += rng.exponential(scale=skew_scale, size=mask.sum())\n",
    "    X = pd.DataFrame(data, columns=[f\"f{j}\" for j in range(n_features)])\n",
    "    y = X.sum(axis=1) + rng.normal(0, 0.1, size=n_obs)\n",
    "    return X, y\n",
    "\n",
    "X, y = make_synthetic(5000, 1, 3, 1, 0, 0, np.random.default_rng(42))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(X.values, bins=50)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HistMethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
