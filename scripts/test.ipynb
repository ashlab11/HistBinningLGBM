{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8220980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: cpu_act, Avg Skew: 5.40, Target Skew: -3.42\n",
      "Dataset: pol, Avg Skew: 4.78, Target Skew: 0.92\n",
      "Dataset: elevators, Avg Skew: -0.60, Target Skew: 2.42\n",
      "Dataset: wine_quality, Avg Skew: 1.36, Target Skew: 0.19\n",
      "Dataset: Ailerons, Avg Skew: 0.60, Target Skew: -1.35\n",
      "Dataset: houses, Avg Skew: 2.23, Target Skew: -0.17\n",
      "Dataset: house_16H, Avg Skew: 6.14, Target Skew: -3.43\n",
      "Dataset: diamonds, Avg Skew: 1.03, Target Skew: 0.12\n",
      "Dataset: Brazilian_houses, Avg Skew: 30.23, Target Skew: 0.30\n",
      "Dataset: Bike_Sharing_Demand, Avg Skew: 0.06, Target Skew: 1.28\n",
      "Dataset: nyc-taxi-green-dec-2016, Avg Skew: 2.56, Target Skew: -0.00\n",
      "Dataset: house_sales, Avg Skew: 2.40, Target Skew: 0.43\n",
      "Dataset: sulfur, Avg Skew: -0.03, Target Skew: 6.72\n",
      "Dataset: medical_charges, Avg Skew: 5.02, Target Skew: 0.88\n",
      "Dataset: MiamiHousing2016, Avg Skew: 0.93, Target Skew: 0.74\n",
      "Dataset: superconduct, Avg Skew: 0.67, Target Skew: 0.86\n",
      "Dataset: yprop_4_1, Avg Skew: -0.29, Target Skew: -2.23\n",
      "Dataset: abalone, Avg Skew: 0.62, Target Skew: 1.11\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "from openml.tasks import list_tasks, TaskType\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, randint, loguniform, ttest_rel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from joblib import Memory\n",
    "from scipy.stats import skew\n",
    "\n",
    "\n",
    "# Import our binning class.\n",
    "# DataBinner should be defined as in our previous example.\n",
    "from src import DataBinner  \n",
    "\n",
    "def get_memory_for_dataset(bin_method, task_id, seed):\n",
    "    \"\"\"\n",
    "    Create (or reuse) a cache folder specific to this dataset/task.\n",
    "    This way, each dataset version has its own cache files.\n",
    "    \"\"\"\n",
    "    cache_dir = os.path.join(\"../cached_datasets\", bin_method, str(task_id), str(seed))\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    return Memory(location=cache_dir, verbose=0)\n",
    "\n",
    "# -------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"sklearn\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightgbm\").setLevel(logging.ERROR)\n",
    "\n",
    "# Parameter distribution for sklearn\n",
    "param_dist_sklearn = {\n",
    "    'gradientboostingregressor__n_estimators': randint(20, 300),\n",
    "    'gradientboostingregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'gradientboostingregressor__max_depth': randint(3, 6),\n",
    "    'gradientboostingregressor__subsample': uniform(0.5, 0.5),\n",
    "    'gradientboostingregressor__max_features': uniform(0.5, 0.5)}\n",
    "\n",
    "# Parameter distribution for LightGBM\n",
    "param_dist_lgbm = {\n",
    "    'lgbmregressor__n_estimators': randint(20, 300),\n",
    "    'lgbmregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'lgbmregressor__num_leaves': randint(8, 64),\n",
    "    'lgbmregressor__subsample': uniform(0.5, 0.5),\n",
    "    'lgbmregressor__colsample_bytree': uniform(0.5, 0.5)\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (GradientBoostingRegressor(), \"SKL\", param_dist_sklearn),\n",
    "    (LGBMRegressor(verbosity=-1, n_jobs=1, random_state=42), \"LGBM\", param_dist_lgbm), \n",
    "]\n",
    "\n",
    "# List of binning methods to experiment with\n",
    "binning_methods = [\n",
    "    #'exact',\n",
    "    'kmeans',\n",
    "    'quantile',\n",
    "    'linspace'\n",
    "]\n",
    "\n",
    "# Retrieve a benchmark suite from OpenML and select a task\n",
    "benchmark_suite = openml.study.get_suite(336) #337 for classification\n",
    "for benchmark_id in range(18):\n",
    "    task_id = benchmark_suite.tasks[benchmark_id]\n",
    "\n",
    "    task = openml.tasks.get_task(task_id)\n",
    "    dataset = task.get_dataset()\n",
    "    name = dataset.name\n",
    "    X, y, _, _ = dataset.get_data(target=task.target_name)\n",
    "    avg_skew = np.mean([skew(X[col]) for col in X.columns])\n",
    "    y_skew = skew(y)\n",
    "    print(f\"Dataset: {name}, Avg Skew: {avg_skew:.2f}, Target Skew: {y_skew:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b0956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== DATASET abalone with 4177.0 observations and 9.0 features =====\n",
      "category\n",
      "0\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "from openml.tasks import list_tasks, TaskType\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import time\n",
    "import warnings\n",
    "import pandas as pd\n",
    "from scipy.stats import uniform, randint, loguniform, ttest_rel\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV, train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from joblib import Memory\n",
    "from sklearn.preprocessing import OneHotEncoder \n",
    "\n",
    "# Import our binning class.\n",
    "# DataBinner should be defined as in our previous example.\n",
    "from src import DataBinner  \n",
    "\n",
    "def get_memory_for_dataset(bin_method, task_id, seed):\n",
    "    \"\"\"\n",
    "    Create (or reuse) a cache folder specific to this dataset/task.\n",
    "    This way, each dataset version has its own cache files.\n",
    "    \"\"\"\n",
    "    cache_dir = os.path.join(\"../cached_datasets\", bin_method, str(task_id), str(seed))\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    return Memory(location=cache_dir, verbose=0)\n",
    "\n",
    "# -------------------------\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "logging.getLogger(\"sklearn\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightgbm\").setLevel(logging.ERROR)\n",
    "\n",
    "# Parameter distribution for sklearn\n",
    "param_dist_sklearn = {\n",
    "    'gradientboostingregressor__n_estimators': randint(20, 300),\n",
    "    'gradientboostingregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'gradientboostingregressor__max_depth': randint(3, 6),\n",
    "    'gradientboostingregressor__subsample': uniform(0.5, 0.5),\n",
    "    'gradientboostingregressor__max_features': uniform(0.5, 0.5)}\n",
    "\n",
    "# Parameter distribution for LightGBM\n",
    "param_dist_lgbm = {\n",
    "    'lgbmregressor__n_estimators': randint(20, 300),\n",
    "    'lgbmregressor__learning_rate': loguniform(0.001, 0.5),\n",
    "    'lgbmregressor__num_leaves': randint(8, 64),\n",
    "    'lgbmregressor__subsample': uniform(0.5, 0.5),\n",
    "    'lgbmregressor__colsample_bytree': uniform(0.5, 0.5)\n",
    "}\n",
    "\n",
    "models = [\n",
    "    (GradientBoostingRegressor(), \"SKL\", param_dist_sklearn),\n",
    "    #(LGBMRegressor(verbosity=-1, n_jobs=1, random_state=42), \"LGBM\", param_dist_lgbm), \n",
    "]\n",
    "\n",
    "# List of binning methods to experiment with\n",
    "binning_methods = [\n",
    "    #'exact',\n",
    "    'kmeans',\n",
    "    'quantile',\n",
    "    'linspace'\n",
    "]\n",
    "\n",
    "# Retrieve a benchmark suite from OpenML and select a task\n",
    "benchmark_suite = openml.study.get_suite(353) #337 for classification\n",
    "benchmark_id = 0\n",
    "task_id = benchmark_suite.tasks[benchmark_id]\n",
    "\n",
    "task = openml.tasks.get_task(task_id)\n",
    "dataset = task.get_dataset()\n",
    "name = dataset.name\n",
    "obs = dataset.qualities['NumberOfInstances']\n",
    "features = dataset.qualities['NumberOfFeatures']\n",
    "print(f\"===== DATASET {name} with {obs} observations and {features} features =====\")\n",
    "\n",
    "\n",
    "# Get X and y\n",
    "X, y = task.get_X_and_y(dataset_format='dataframe')\n",
    "transform_cols = []\n",
    "for col_idx, dtype in enumerate(X.dtypes):\n",
    "    if dtype == 'object' or dtype == 'category':\n",
    "        transform_cols.append(X.columns[col_idx])\n",
    "\n",
    "# Transform categorical columns to one-hot\n",
    "X = pd.get_dummies(X, columns=transform_cols, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9db726bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def centred_linspace(span, n_modes):\n",
    "    if n_modes == 1:\n",
    "        return np.array([0.0])\n",
    "    return np.linspace(-span, span, n_modes)\n",
    "\n",
    "\n",
    "def make_synthetic(n_obs, n_features, n_modes, mode_size, skew_factor, skew_scale, rng):\n",
    "    \"\"\"Return DataFrame X and target y.\n",
    "    Parameters:\n",
    "    -----------\n",
    "    n_obs : int\n",
    "        Number of observations.\n",
    "    n_features : int\n",
    "        Number of features.\n",
    "    n_modes : int\n",
    "        Number of modes in the multimodal distribution.\n",
    "    mode_size : float\n",
    "        Difference between modes.\n",
    "    skew_factor : float\n",
    "        Probability of adding skewness.\n",
    "    skew_scale : float\n",
    "        Scale of the skewness.\n",
    "    rng : np.random.Generator\n",
    "        Random number generator.\n",
    "    Returns:\n",
    "    --------\n",
    "    X : pd.DataFrame\n",
    "        DataFrame with n_obs rows and n_features columns.\n",
    "    \"\"\"\n",
    "    data = np.zeros((n_obs, n_features))\n",
    "    # --- Multimodal component\n",
    "    means = np.linspace(0, mode_size * (n_modes - 1), n_modes)\n",
    "    for j in range(n_features):\n",
    "        mode_choice = rng.integers(0, n_modes, size=n_obs)\n",
    "        data[:, j] = rng.normal(loc=means[mode_choice], scale=1.0)\n",
    "        data[:, j] = (data[:, j] - data[:, j].mean()) / data[:, j].std() # Standardizing\n",
    "    \n",
    "    # --- Skewness: add positive outliers with prob = skew_factor\n",
    "    if skew_factor > 0:\n",
    "        mask = rng.random(size=data.shape) < skew_factor\n",
    "        data[mask] += rng.exponential(scale=skew_scale, size=mask.sum())\n",
    "    X = pd.DataFrame(data, columns=[f\"f{j}\" for j in range(n_features)])\n",
    "    y = X.sum(axis=1) + rng.normal(0, 0.1, size=n_obs)\n",
    "    return X, y\n",
    "\n",
    "X, y = make_synthetic(5000, 1, 10, 5, 0, 0, np.random.default_rng(42))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(X.values, bins=50)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f368bc7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative values in the dataset: 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "negative_vals = 0\n",
    "for idx in range(1, 6):\n",
    "    exp = np.load(f'../d{idx}.npy')\n",
    "    mean = np.mean(exp, axis=2)\n",
    "    negative_vals += np.sum(mean < 0)\n",
    "    \n",
    "print(f\"Negative values in the dataset: {negative_vals}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HistMethods",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
